---
# Admin-only tasks for Ceph cluster deployment

- name: Collect all host information
  set_fact:
    all_hosts_info: "{{ all_hosts_info | default([]) + [hostvars[item].host_info] }}"
  loop: "{{ groups['ceph_nodes'] }}"

- name: Get admin node info
  set_fact:
    admin_node_info: "{{ all_hosts_info | selectattr('hostname', 'equalto', groups['admin'][0]) | first }}"

- name: Create Ceph nodes inventory file
  copy:
    content: |
      # Ceph Cluster Inventory
      # Generated by Ansible
      
      [ceph_nodes]
      {% for host in groups['ceph_nodes'] %}
      {{ host }} ansible_host={{ hostvars[host].ansible_host }} ansible_user=root
      {% endfor %}
      
      [admin]
      {{ groups['admin'][0] }} ansible_host={{ hostvars[groups['admin'][0]].ansible_host }} ansible_user=root
      
      [all:vars]
      ansible_ssh_common_args='-o StrictHostKeyChecking=no'
      ansible_become=yes
    dest: /root/ceph-inventory.ini
    mode: '0644'

- name: Create cluster spec file from template
  template:
    src: cluster-spec.j2
    dest: "{{ cluster_spec_file }}"
    mode: '0644'

- name: Check if SSH key pair already exists
  stat:
    path: /root/.ssh/id_rsa
  register: ssh_private_key_exists

- name: Check if SSH public key already exists
  stat:
    path: /root/.ssh/id_rsa.pub
  register: ssh_public_key_exists

- name: Generate SSH key pair on admin host (only if not exists)
  openssh_keypair:
    path: /root/.ssh/id_rsa
    type: rsa
    size: 2048
    state: present
    force: no
  when: not ssh_private_key_exists.stat.exists or not ssh_public_key_exists.stat.exists

- name: Read admin host public key
  slurp:
    src: /root/.ssh/id_rsa.pub
  register: admin_ssh_public_key

- name: Ensure SSH service is running on all nodes
  systemd:
    name: sshd
    state: started
    enabled: yes
  delegate_to: "{{ item }}"
  loop: "{{ groups['ceph_nodes'] }}"

- name: Add admin host public key to all cluster nodes
  authorized_key:
    user: root
    state: present
    key: "{{ admin_ssh_public_key.content | b64decode }}"
  delegate_to: "{{ item }}"
  loop: "{{ groups['ceph_nodes'] }}"

- name: Configure SSH client on admin host for non-interactive usage
  copy:
    content: |
      Host *
          StrictHostKeyChecking no
          UserKnownHostsFile /dev/null
          LogLevel QUIET
          ConnectTimeout 10
    dest: /root/.ssh/config
    mode: '0600'

- name: Test passwordless SSH connectivity to all nodes
  shell: |
    failed_hosts=""
    echo "Testing SSH connectivity to all cluster nodes..."
    {% for host in groups['ceph_nodes'] %}
    echo "Testing {{ host }}..."
    if ! ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 {{ host }} "hostname && echo 'SSH OK'" 2>/dev/null; then
      echo "FAILED: SSH connectivity to {{ host }}"
      failed_hosts="${failed_hosts} {{ host }}"
    fi
    {% endfor %}
    
    if [ ! -z "$failed_hosts" ]; then
      echo "SSH connectivity failed to nodes:$failed_hosts"
      echo "Ceph deployment cannot continue without SSH access to all nodes"
      exit 1
    fi
    echo "SSH connectivity test passed for all nodes"
  register: ssh_test_result
  retries: 2
  delay: 10

- name: Create registry authentication JSON file
  copy:
    content: |
      {
        "url": "{{ registry_url }}",
        "username": "{{ registry_username }}",
        "password": "{{ registry_password }}"
      }
    dest: /etc/ceph-registry-auth.json
    mode: '0600'

- name: Bootstrap Ceph cluster
  shell: |
    echo "Starting Ceph cluster bootstrap..."
    cephadm bootstrap \
      --apply-spec {{ cluster_spec_file }} \
      --cluster-network {{ storage_mgmt_network }} \
      --mon-ip {{ admin_node_info.storage_ip }} \
      --registry-json /etc/ceph-registry-auth.json \
      {% if ceph_allow_fqdn_hostname %}--allow-fqdn-hostname{% endif %}
  register: ceph_bootstrap_result
  ignore_errors: true

- name: Show bootstrap output on failure
  debug:
    msg: |
      Ceph bootstrap failed!
      Command exit code: {{ ceph_bootstrap_result.rc }}
      Error output: {{ ceph_bootstrap_result.stderr_lines | default([]) | join('\n') }}
      Full output: {{ ceph_bootstrap_result.stdout_lines | default([]) | join('\n') }}
  when: ceph_bootstrap_result.rc != 0

- name: Fail deployment if bootstrap failed
  fail:
    msg: "Ceph bootstrap failed - cannot continue with cluster deployment"
  when: ceph_bootstrap_result.rc != 0

- name: Verify bootstrap success
  shell: ceph status
  register: ceph_status_check
  when: ceph_bootstrap_result.rc == 0

- name: Apply monitor service using labels
  shell: ceph orch apply mon label:mon
  register: ceph_mon_apply_result

- name: Display monitor service apply result
  debug:
    msg: "{{ ceph_mon_apply_result.stdout_lines }}"

- name: Apply manager service
  shell: ceph orch apply mgr 3
  register: ceph_mgr_apply_result

- name: Display manager service apply result
  debug:
    msg: "{{ ceph_mgr_apply_result.stdout_lines }}"

- name: Zap unused devices
  shell: |
    ceph orch device ls | grep "No" | awk '{print $1, $2}' | while read host dev; do 
      ceph orch device zap "${host}" "${dev}" --force
    done
  register: ceph_device_zap_result

- name: Display device zap result
  debug:
    msg: "{{ ceph_device_zap_result.stdout_lines }}"
  when: ceph_device_zap_result.stdout_lines is defined

- name: Apply OSDs to all available devices
  shell: ceph orch apply osd --all-available-devices
  register: ceph_osd_apply_result

- name: Display OSD apply result
  debug:
    msg: "{{ ceph_osd_apply_result.stdout_lines }}"

- name: Wait for cluster stabilization
  pause:
    seconds: "{{ ceph_stabilization_wait_timeout }}"

- name: Check initial cluster health
  shell: ceph health
  register: initial_health_check
  ignore_errors: true

- name: Show initial cluster status
  debug:
    msg: "Initial cluster health: {{ initial_health_check.stdout }}"

- name: Set cluster health check flag
  set_fact:
    cluster_is_healthy: "{{ initial_health_check.stdout == 'HEALTH_OK' }}"

- name: Health check and recovery attempts
  include_tasks: health_check_tasks.yml
  vars:
    attempt_number: "{{ item }}"
  loop: "{{ range(1, ceph_health_check_retries + 1) | list }}"
  when: initial_health_check.stdout != 'HEALTH_OK'

- name: Final cluster health check
  shell: ceph health
  register: final_health_status
  ignore_errors: true

- name: Display final cluster health 
  debug:
    msg: "Final cluster health: {{ final_health_status.stdout }}"

- name: Fail deployment if cluster unhealthy
  fail:
    msg: "Ceph cluster deployment failed. Final health status: {{ final_health_status.stdout }}"
  when: final_health_status.stdout != 'HEALTH_OK'

- name: Print admin node hostname
  debug:
    msg: "Admin node: {{ groups['admin'][0] }}"
